{"num_layers": 4, "units_0": 64, "kernel_size_0": 5, "dropout_0": 0.13301692145850905, "activation_0": "gelu", "units_1": 64, "kernel_size_1": 15, "dropout_1": 0.3523656597531605, "activation_1": "relu", "units_2": 32, "kernel_size_2": 7, "dropout_2": 0.43089965048003454, "activation_2": "relu", "units_3": 32, "kernel_size_3": 5, "dropout_3": 0.38756086841078874, "activation_3": "silu", "lr": 0.0009977292779053044}